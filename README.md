Cas d'utilisation Big Data Banque Utilisant Hadoop
Aujourd'hui, nous allons étudier un cas d'utilisation du Big Data au quotidien, notamment dans le secteur bancaire.
## Préparation requise :
1. Vous avez correctement installé le JDK Java (Java 8 est recommandé).
2. Vous avez correctement installé Apache Hadoop (3.2.4), Apache Hive (3.1.3) et Apache Sqoop (1.4.7).
3. Vous avez correctement installé MySQL. ## Partie 1 : Saisie de données bancaires fictives dans MySQL
Cette section sera expliquée dans la « Partie 1 »
## Partie 2 : Exportation de données MySQL vers Apache Hadoop HDFS avec Apache Sqoop
Cette section sera expliquée dans la « Partie 2 »
## Partie 3 : Création d’une table externe dans Apache Hive
Cette section sera expliquée dans la « Partie 3 »
## Partie 4 : Implémentation des processus de chiffrement et de déchiffrement des données dans Apache Hive à l’aide de fonctions définies par l’utilisateur (UDF)
Cette section sera expliquée dans la « Partie 4 »
## Partie 5 : Analyse des processus de chiffrement et de déchiffrement des données dans Apache Hive
Cette section sera expliquée dans la « Partie 5 »
